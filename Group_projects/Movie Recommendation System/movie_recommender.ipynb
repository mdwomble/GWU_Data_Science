{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOABrlU6VzbPR9uWQjhPpo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxwellowusu/movie_recommender_system_ML/blob/main/movie_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bJdNLeUQ1mh"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q scann"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow_recommenders as tfrs"
      ],
      "metadata": {
        "id": "nxxfy7PmAH91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "vaNkWkNLARm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings data.\n",
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "# Features of all the available movies.\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
      ],
      "metadata": {
        "id": "ieCGfYP5AIA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check info of rating dataset\n",
        "for x in ratings.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ],
      "metadata": {
        "id": "dja9q8lJAID6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check info of movie dataset\n",
        "for x in movies.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ],
      "metadata": {
        "id": "g8Y1dtjqAIGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get required columns\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "})\n",
        "movies = movies.map(lambda x: x[\"movie_title\"])"
      ],
      "metadata": {
        "id": "qm4QdjWjAIJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data into train and test"
      ],
      "metadata": {
        "id": "97Bdf1DEAzh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)"
      ],
      "metadata": {
        "id": "4u1WKvanAILz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge dataset\n",
        "movie_titles = movies.batch(1_000)\n",
        "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
        "\n",
        "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
        "\n",
        "unique_movie_titles[:10]"
      ],
      "metadata": {
        "id": "3_WINEFEAIOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling "
      ],
      "metadata": {
        "id": "lV_2TNbdBWhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query tower\n",
        "embedding_dimension = 32"
      ],
      "metadata": {
        "id": "cP0wStpiAISH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_user_ids, mask_token=None),\n",
        "  # We add an additional embedding to account for unknown tokens.\n",
        "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "])"
      ],
      "metadata": {
        "id": "nWVI0VpDBhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Candidate tower\n",
        "movie_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_movie_titles, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
        "])"
      ],
      "metadata": {
        "id": "X3d8FlzwBhbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric\n",
        "\n",
        "metrics = tfrs.metrics.FactorizedTopK(\n",
        "  candidates=movies.batch(128).map(movie_model)\n",
        ")\n",
        "\n",
        "# Loss\n",
        "task = tfrs.tasks.Retrieval(\n",
        "  metrics=metrics\n",
        ")"
      ],
      "metadata": {
        "id": "Dxe9AtuYBhd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Model\n",
        "\n",
        "class MovielensModel(tfrs.Model):\n",
        "\n",
        "  def __init__(self, user_model, movie_model):\n",
        "    super().__init__()\n",
        "    self.movie_model: tf.keras.Model = movie_model\n",
        "    self.user_model: tf.keras.Model = user_model\n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    # And pick out the movie features and pass them into the movie model,\n",
        "    # getting embeddings back.\n",
        "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(user_embeddings, positive_movie_embeddings)"
      ],
      "metadata": {
        "id": "11GsQ_s-Bhgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoBaseClassMovielensModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, user_model, movie_model):\n",
        "    super().__init__()\n",
        "    self.movie_model: tf.keras.Model = movie_model\n",
        "    self.user_model: tf.keras.Model = user_model\n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "  def train_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "\n",
        "    # Set up a gradient tape to record gradients.\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # Loss computation.\n",
        "      user_embeddings = self.user_model(features[\"user_id\"])\n",
        "      positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "      loss = self.task(user_embeddings, positive_movie_embeddings)\n",
        "\n",
        "      # Handle regularization losses as well.\n",
        "      regularization_loss = sum(self.losses)\n",
        "\n",
        "      total_loss = loss + regularization_loss\n",
        "\n",
        "    gradients = tape.gradient(total_loss, self.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "    metrics = {metric.name: metric.result() for metric in self.metrics}\n",
        "    metrics[\"loss\"] = loss\n",
        "    metrics[\"regularization_loss\"] = regularization_loss\n",
        "    metrics[\"total_loss\"] = total_loss\n",
        "\n",
        "    return metrics\n",
        "\n",
        "  def test_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "\n",
        "    # Loss computation.\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "    loss = self.task(user_embeddings, positive_movie_embeddings)\n",
        "\n",
        "    # Handle regularization losses as well.\n",
        "    regularization_loss = sum(self.losses)\n",
        "\n",
        "    total_loss = loss + regularization_loss\n",
        "\n",
        "    metrics = {metric.name: metric.result() for metric in self.metrics}\n",
        "    metrics[\"loss\"] = loss\n",
        "    metrics[\"regularization_loss\"] = regularization_loss\n",
        "    metrics[\"total_loss\"] = total_loss\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "3s9_-lqqBhjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit and evaluate the model"
      ],
      "metadata": {
        "id": "z39t6jflDPmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MovielensModel(user_model, movie_model)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ],
      "metadata": {
        "id": "PrNsPdoaBhm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffling \n",
        "\n",
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "metadata": {
        "id": "AFv3JWrmDfBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting\n",
        "model.fit(cached_train, epochs=10)"
      ],
      "metadata": {
        "id": "FW4ScHMEDfES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "model.evaluate(cached_test, return_dict=True)"
      ],
      "metadata": {
        "id": "R6J7SLPODfH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Prediction"
      ],
      "metadata": {
        "id": "_jEacsvrD-71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model that takes in raw query features, and\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "# recommends movies out of the entire movies dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
        ")\n",
        "\n",
        "# Get recommendations.\n",
        "_, titles = index(tf.constant([\"42\"]))\n",
        "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
      ],
      "metadata": {
        "id": "JK1Y71WSEBB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Serving or Deployment"
      ],
      "metadata": {
        "id": "zW77QOlNEOFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the query model.\n",
        "with tempfile.TemporaryDirectory() as tmp:\n",
        "  path = os.path.join(tmp, \"model\")\n",
        "\n",
        "  # Save the index.\n",
        "  tf.saved_model.save(index, path)\n",
        "\n",
        "  # Load it back; can also be done in TensorFlow Serving.\n",
        "  loaded = tf.saved_model.load(path)\n",
        "\n",
        "  # Pass a user id in, get top predicted movie titles back.\n",
        "  scores, titles = loaded([\"42\"])\n",
        "\n",
        "  print(f\"Recommendations: {titles[0][:3]}\")"
      ],
      "metadata": {
        "id": "4ocVd66LEBFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.user_model)\n",
        "scann_index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
        ")"
      ],
      "metadata": {
        "id": "i6b9sDM5EBHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get recommendations.\n",
        "_, titles = scann_index(tf.constant([\"40\"]))\n",
        "print(f\"Recommendations for user 40: {titles[0, :3]}\")"
      ],
      "metadata": {
        "id": "NXg0_QMrEBKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the query model.\n",
        "with tempfile.TemporaryDirectory() as tmp:\n",
        "  path = os.path.join(tmp, \"model\")\n",
        "\n",
        "  # Save the index.\n",
        "  tf.saved_model.save(\n",
        "      scann_index,\n",
        "      path,\n",
        "      options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
        "  )\n",
        "\n",
        "  # Load it back; can also be done in TensorFlow Serving.\n",
        "  loaded = tf.saved_model.load(path)\n",
        "\n",
        "  # Pass a user id in, get top predicted movie titles back.\n",
        "  scores, titles = loaded([\"40\"])\n",
        "\n",
        "  print(f\"Recommendations: {titles[0][:3]}\")"
      ],
      "metadata": {
        "id": "xRW5hSMzEBNv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}